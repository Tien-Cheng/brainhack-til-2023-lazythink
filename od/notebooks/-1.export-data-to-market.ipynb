{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGE_DIR = \"../data/images/train\"\n",
    "TRAIN_ANNOTATION_DIR = \"../data/labels/yolo/train_labels\"\n",
    "VAL_IMAGE_DIR = \"../data/images/validation\"\n",
    "VAL_ANNOTATION_DIR = \"../data/labels/yolo/val_labels\"\n",
    "\n",
    "EXPORT_TRAIN_DIR = \"../data/market1501/bounding_box_train\"\n",
    "EXPORT_TEST_DIR  = \"../data/market1501/bounding_box_test\"   # With label\n",
    "EXPORT_QUERY_DIR = \"../data/market1501/gt_query\"  # With label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = Path(TRAIN_IMAGE_DIR)\n",
    "train_annotation_dir = Path(TRAIN_ANNOTATION_DIR)\n",
    "val_image_dir = Path(VAL_IMAGE_DIR)\n",
    "val_annotation_dir = Path(VAL_ANNOTATION_DIR)\n",
    "\n",
    "export_train_dir = Path(EXPORT_TRAIN_DIR)\n",
    "export_test_dir = Path(EXPORT_TEST_DIR)\n",
    "export_query_dir = Path(EXPORT_QUERY_DIR)\n",
    "\n",
    "export_train_dir.mkdir(parents=True, exist_ok=True)\n",
    "export_test_dir.mkdir(parents=True, exist_ok=True)\n",
    "export_query_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5664it [03:41, 25.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Export cropped train data\n",
    "for label_path in tqdm.tqdm(train_annotation_dir.glob(\"*.txt\")):\n",
    "    with open(label_path) as f:\n",
    "        for idx, label_infos in enumerate(f.readlines()):\n",
    "            [c, n_x, n_y, n_w, n_h] = map(float, label_infos.split(\" \"))\n",
    "\n",
    "            # Load image\n",
    "            img = Image.open(\n",
    "                train_image_dir / label_path.name.replace(\".txt\", \".png\")\n",
    "            ).convert(\"RGB\")\n",
    "\n",
    "            # Convert yolo bbox to PIL bbox\n",
    "            left = (n_x - n_w / 2) * img.width\n",
    "            top = (n_y - n_h / 2) * img.height\n",
    "            right = (n_x + n_w / 2) * img.width\n",
    "            bottom = (n_y + n_h / 2) * img.height\n",
    "\n",
    "            # Crop plushie\n",
    "            cropped_img = img.crop((left, top, right, bottom))\n",
    "\n",
    "            # Save cropped plushie\n",
    "            cropped_img.save(\n",
    "                export_train_dir / f\"{int(c)}_c1s1_{label_path.stem}_{idx}.jpg\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [00:31, 25.26it/s]\n"
     ]
    }
   ],
   "source": [
    "suspect_file_ids = [607, 623, 131, 24, 47, 282, 129, 55, 125, 569, 58, 259, 290, 23, 302, 103, 264, 249, 308, 590, 44, 272, 621, 102, 615, 150, 291, 561, 262, 284, 582, 586, 589, 604, 113, 576, 572, 119, 260, 144, 38, 265, 612, 41, 271, 602, 27, 153, 112, 636, 157, 118, 571, 266, 578, 17, 251, 279, 18, 159, 301, 306, 609, 285, 567, 6, 281, 152, 634, 49, 87, 599, 632, 84, 73, 134, 14, 34, 562, 155, 48, 581, 151, 316, 105, 287, 250, 294, 631, 313, 3, 610, 588, 78, 598, 85, 277, 62, 603, 109]\n",
    "\n",
    "# Export cropped test data\n",
    "for label_path in tqdm.tqdm(val_annotation_dir.glob(\"*.txt\")):\n",
    "    with open(label_path) as f:\n",
    "        for idx, label_infos in enumerate(f.readlines()):\n",
    "            [c, n_x, n_y, n_w, n_h] = map(float, label_infos.split(\" \"))\n",
    "\n",
    "            # Load image\n",
    "            img = Image.open(\n",
    "                val_image_dir / label_path.name.replace(\".txt\", \".png\")\n",
    "            ).convert(\"RGB\")\n",
    "\n",
    "            # Convert yolo bbox to PIL bbox\n",
    "            left = (n_x - n_w / 2) * img.width\n",
    "            top = (n_y - n_h / 2) * img.height\n",
    "            right = (n_x + n_w / 2) * img.width\n",
    "            bottom = (n_y + n_h / 2) * img.height\n",
    "\n",
    "            # Crop plushie\n",
    "            cropped_img = img.crop((left, top, right, bottom))\n",
    "\n",
    "            # Save cropped plushie\n",
    "            if int(label_path.stem.replace(\"image_\", \"\")) in suspect_file_ids:\n",
    "                # Save to suspect dir\n",
    "                cropped_img.save(\n",
    "                    export_query_dir / f\"{int(c)}_c1s1_{label_path.stem}_{idx}.jpg\"\n",
    "                )\n",
    "            else:\n",
    "                # Save to test dir\n",
    "                cropped_img.save(\n",
    "                    export_test_dir / f\"{int(c)}_c1s1_{label_path.stem}_{idx}.jpg\"\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://../data/market1501.zip [Content-Type=application/zip]...\n",
      "| [1 files][ 56.8 MiB/ 56.8 MiB]                                                \n",
      "Operation completed over 1 objects/56.8 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Zip market data folder and uplaod to gcs\n",
    "\n",
    "!cd ../data/market1501; zip -r ../market1501.zip *\n",
    "!gsutil cp ../data/market1501.zip gs://cloud-ai-platform-e8edc327-855c-4911-bb8e-205517f8c899/cv/market1501.zip\n",
    "!rm ../data/market1501.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainhack-od",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
